{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e809cb8",
   "metadata": {},
   "source": [
    "# Aplicaciones en el Análisis de Eficiencia Algorítmica\n",
    "\n",
    "### **Introducción**\n",
    "\n",
    "En el corazón del diseño y análisis de algoritmos yace la necesidad imperativa de comprender su eficiencia. Las ecuaciones de recurrencia, al describir el comportamiento de algoritmos recursivos, son una herramienta matemática clave para este propósito. Permiten a los teóricos y desarrolladores de algoritmos predecir cómo cambia el rendimiento de un algoritmo con variaciones en el tamaño del problema. Esta clase se sumerge en cómo el dominio de las ecuaciones de recurrencia mejora nuestra capacidad para evaluar, seleccionar y diseñar algoritmos óptimos.\n",
    "\n",
    "### **Evaluación de la Eficiencia Algorítmica**\n",
    "\n",
    "La eficiencia de un algoritmo se mide típicamente en términos de su tiempo de ejecución y uso de espacio, en función del tamaño de entrada. Las ecuaciones de recurrencia modelan esta relación, ofreciendo una vista clara de cómo el algoritmo escala. Por ejemplo, un algoritmo de división y conquista como el Merge Sort puede tener su eficiencia expresada mediante una ecuación de recurrencia que refleja cómo se descompone el problema y el costo asociado a esta descomposición y la subsiguiente combinación de resultados.\n",
    "\n",
    "### **Selección de Algoritmos para Aplicaciones Prácticas**\n",
    "\n",
    "El análisis mediante ecuaciones de recurrencia informa la selección de algoritmos adecuados para problemas específicos. Al comparar la complejidad de diferentes algoritmos, podemos elegir aquellos que minimizan el tiempo de ejecución y el uso de recursos. Este proceso es crucial en contextos donde los recursos son limitados o el rendimiento es crítico, como en sistemas embebidos o aplicaciones de tiempo real.\n",
    "\n",
    "### **Diseño de Algoritmos Eficientes**\n",
    "\n",
    "Además de evaluar algoritmos existentes, las ecuaciones de recurrencia inspiran el diseño de nuevos algoritmos. Al entender las implicaciones de ciertas estrategias de descomposición del problema, los diseñadores pueden idear métodos recursivos que minimizan el costo computacional. Este enfoque es particularmente relevante en la investigación y desarrollo de algoritmos para campos emergentes, donde los problemas pueden no tener soluciones bien establecidas.\n",
    "\n",
    "### **Técnicas Avanzadas de Resolución**\n",
    "\n",
    "Más allá de la sustitución y el árbol de recurrencia, el análisis amortizado y las técnicas de programación dinámica ofrecen métodos sofisticados para descomponer y resolver recurrencias. Estas técnicas permiten una comprensión más profunda de la eficiencia a largo plazo de los algoritmos, especialmente en casos donde el peor escenario es raro o el costo promedio es significativamente más representativo del rendimiento real.\n",
    "\n",
    "### **Casos de Estudio y Aplicaciones**\n",
    "\n",
    "Examinar casos de estudio específicos, como algoritmos de ordenación, búsqueda y grafos, ilustra la aplicación práctica de las ecuaciones de recurrencia en el análisis de eficiencia. Por ejemplo, el análisis de QuickSort revela cómo su comportamiento promedio es O(n log n), mientras que su peor caso es O(n^2), y cómo las técnicas de selección de pivote pueden influir en su eficiencia práctica.\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Las ecuaciones de recurrencia son más que una herramienta teórica; son fundamentales para el ciclo de vida completo de los algoritmos, desde la conceptualización hasta la implementación. Su uso en el análisis de eficiencia algorítmica asegura que podemos diseñar y seleccionar algoritmos que no solo resuelven problemas, sino que lo hacen de la manera más óptima posible. Así, el dominio de estas ecuaciones y las técnicas para resolverlas es esencial para cualquier profesional de la informática que busque desarrollar soluciones efectivas y eficientes en el mundo computacionalmente complejo de hoy.\n",
    "\n",
    "---\n",
    "\n",
    "Para explorar las aplicaciones en el análisis de eficiencia algorítmica, especialmente en algoritmos de clasificación y aprendizaje automático, así como en el análisis de casos promedio versus peor caso en algoritmos, diseñaremos ejercicios prácticos. Estos ejercicios te permitirán aplicar conceptos de probabilidad y estadística a la evaluación de algoritmos y profundizar en el análisis de su rendimiento.\n",
    "\n",
    "## **Ejercicios**\n",
    "\n",
    "### **Ejercicio 1: Análisis Probabilístico de QuickSort**\n",
    "\n",
    "El algoritmo QuickSort es conocido por su eficiencia en el caso promedio, aunque su peor caso es significativamente menos eficiente. Realiza un análisis estadístico para comparar el caso promedio y el peor caso del tiempo de ejecución de QuickSort.\n",
    "\n",
    "1. Implementa el algoritmo QuickSort en Python.\n",
    "2. Diseña un experimento que mida el tiempo de ejecución del algoritmo con arreglos de diferentes tamaños, en dos escenarios: cuando los arreglos están ordenados aleatoriamente (caso promedio) y cuando están ordenados de manera ascendente o descendente (peor caso).\n",
    "3. Utiliza la biblioteca `time` para medir el tiempo de ejecución y la biblioteca `matplotlib` para graficar los resultados.\n",
    "\n",
    "### **Ejercicio 2: Evaluación de un Clasificador Binario**\n",
    "\n",
    "Considera un clasificador binario simple, como la regresión logística, aplicado a un conjunto de datos sintéticos.\n",
    "\n",
    "1. Utiliza `sklearn` para generar un conjunto de datos binarios sintéticos y ajustar un modelo de regresión logística.\n",
    "2. Calcula y compara las métricas de rendimiento (precisión, recall, F1-score) en el conjunto de entrenamiento y un conjunto de prueba.\n",
    "3. Analiza cómo la división de los datos entre entrenamiento y prueba afecta el rendimiento del modelo.\n",
    "\n",
    "### **Ejercicio 3: Análisis de Complejidad de Búsqueda Binaria**\n",
    "\n",
    "La búsqueda binaria es un ejemplo de un algoritmo con un excelente caso promedio y peor caso de complejidad temporal.\n",
    "\n",
    "1. Implementa la búsqueda binaria en Python.\n",
    "2. Demuestra mediante un experimento cómo el tamaño del arreglo afecta el tiempo de ejecución, tanto en el mejor como en el peor caso. Considera arreglos de tamaño desde 10 hasta 10,000 elementos.\n",
    "3. Grafica tus resultados, mostrando cómo el tiempo de ejecución varía con el tamaño del arreglo.\n",
    "\n",
    "### **Ejercicio 4: Simulación Monte Carlo para Estimar π**\n",
    "\n",
    "Este ejercicio no está directamente relacionado con algoritmos de clasificación o aprendizaje automático pero es un excelente ejemplo de cómo la estadística y la probabilidad se aplican en el análisis algorítmico.\n",
    "\n",
    "1. Implementa una simulación de Monte Carlo en Python para estimar el valor de π.\n",
    "2. Realiza la simulación con diferentes números de puntos (por ejemplo, 100, 1,000, 10,000, y 100,000) y observa cómo la precisión de la estimación de π mejora con más puntos.\n",
    "3. Explica el concepto de \"Ley de los Grandes Números\" en el contexto de tu simulación.\n",
    "\n",
    "### **Ejercicio 5: Análisis de Algoritmo de Ordenación por Mezcla (Merge Sort)**\n",
    "\n",
    "Analiza el algoritmo Merge Sort desde la perspectiva del caso promedio y el peor caso.\n",
    "\n",
    "1. Implementa Merge Sort en Python.\n",
    "2. Considera arreglos de entrada de diferentes tamaños y estados (aleatorios, casi ordenados, ordenados inversamente) para evaluar el rendimiento del algoritmo.\n",
    "3. Mide el tiempo de ejecución en estos diferentes escenarios y discute si hay alguna diferencia significativa entre el caso promedio y el peor caso.\n",
    "\n",
    "### **Soluciones Propuestas**\n",
    "\n",
    "Debido a la naturaleza práctica de estos ejercicios, las soluciones detalladas involucrarían la implementación de código, análisis estadístico, y la interpretación de los resultados obtenidos. Si bien no puedo ejecutar código ni generar gráficos en tiempo real, las directrices proporcionadas te ofrecen un marco sobre cómo abordar cada problema, implementar las soluciones en Python, y utilizar bibliotecas relevantes como `matplotlib` para la visualización y `sklearn` para el aprendizaje automático.\n",
    "\n",
    "Estos ejercicios están diseñados para aplicar y profundizar tu comprensión de la eficiencia algorítmica en contextos prácticos, reforzando la importancia del análisis estadístico y probabilístico en el diseño y evaluación de algoritmos.\n",
    "\n",
    "---\n",
    "\n",
    "Vamos a desarrollar soluciones detalladas y completas para los ejercicios propuestos, enfocándonos en aplicaciones prácticas de análisis de eficiencia algorítmica. Aunque no pueda ejecutar código directamente, te proporcionaré implementaciones detalladas en Python y explicaciones para guiar el análisis y la experimentación.\n",
    "\n",
    "### **Ejercicio 1: Análisis Probabilístico de QuickSort**\n",
    "\n",
    "### **Implementación de QuickSort en Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    else:\n",
    "        pivot = arr[len(arr) // 2]\n",
    "        left = [x for x in arr if x < pivot]\n",
    "        middle = [x for x in arr if x == pivot]\n",
    "        right = [x for x in arr if x > pivot]\n",
    "        return quicksort(left) + middle + quicksort(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8482f2",
   "metadata": {},
   "source": [
    "### **Experimento y Análisis de Tiempo de Ejecución:**\n",
    "\n",
    "Para medir el tiempo de ejecución, puedes utilizar el módulo `time` de Python. Genera arreglos de diferentes tamaños, tanto ordenados aleatoriamente como ordenados de manera ascendente, y mide el tiempo que toma QuickSort para ordenarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5680b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def medir_tiempo(arr):\n",
    "    inicio = time.time()\n",
    "    quicksort(arr)\n",
    "    fin = time.time()\n",
    "    return fin - inicio\n",
    "\n",
    "# Genera arreglos de diferentes tamaños\n",
    "tamaños = [100, 1000, 10000, 100000]\n",
    "tiempos_promedio = []\n",
    "tiempos_peor_caso = []\n",
    "\n",
    "for tamaño in tamaños:\n",
    "    arr_promedio = [random.randint(0, tamaño) for _ in range(tamaño)]\n",
    "    arr_peor_caso = list(range(tamaño))  # Orden ascendente\n",
    "\n",
    "    tiempo_promedio = medir_tiempo(arr_promedio)\n",
    "    tiempo_peor_caso = medir_tiempo(arr_peor_caso)\n",
    "\n",
    "    tiempos_promedio.append(tiempo_promedio)\n",
    "    tiempos_peor_caso.append(tiempo_peor_caso)\n",
    "\n",
    "# Grafica los resultados\n",
    "plt.plot(tamaños, tiempos_promedio, label='Caso Promedio')\n",
    "plt.plot(tamaños, tiempos_peor_caso, label='Peor Caso')\n",
    "plt.xlabel('Tamaño del Arreglo')\n",
    "plt.ylabel('Tiempo de Ejecución (s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e4b88",
   "metadata": {},
   "source": [
    "### **Ejercicio 2: Evaluación de un Clasificador Binario**\n",
    "\n",
    "### **Generación de Datos y Ajuste del Modelo:**\n",
    "\n",
    "Utiliza `sklearn.datasets.make_classification` para generar datos y `sklearn.linear_model.LogisticRegression` para ajustar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2070a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Genera un conjunto de datos binarios sintéticos\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajusta un modelo de regresión logística\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo\n",
    "predicciones = modelo.predict(X_test)\n",
    "print(classification_report(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604641b",
   "metadata": {},
   "source": [
    "### **Ejercicio 3: Análisis de Complejidad de Búsqueda Binaria**\n",
    "\n",
    "### **Implementación de Búsqueda Binaria:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_binaria(lista, elemento):\n",
    "    inicio, fin = 0, len(lista) - 1\n",
    "    while inicio <= fin:\n",
    "        medio = (inicio + fin) // 2\n",
    "        if lista[medio] == elemento:\n",
    "            return medio\n",
    "        elif lista[medio] < elemento:\n",
    "            inicio = medio + 1\n",
    "        else:\n",
    "            fin = medio - 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9fd06",
   "metadata": {},
   "source": [
    "### **Experimento de Tiempo de Ejecución:**\n",
    "\n",
    "Reutiliza el enfoque de medición de tiempo del Ejercicio 1, pero esta vez con la función `busqueda_binaria`. Genera arreglos ordenados de diferentes tamaños y mide el tiempo que toma encontrar un elemento (puedes elegir el último para simular el peor caso).\n",
    "\n",
    "### **Ejercicio 4: Simulación Monte Carlo para Estimar π**\n",
    "\n",
    "### **Implementación de la Simulación:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def estimar_pi(num_puntos):\n",
    "    puntos_dentro_circulo = 0\n",
    "    for _ in range(num_puntos):\n",
    "        x, y = random.random(), random.random()\n",
    "        if x**2 + y**2 <= 1:\n",
    "            puntos_dentro_circulo += 1\n",
    "    return 4 * puntos_dentro_circulo / num_puntos\n",
    "\n",
    "# Ejemplo de uso\n",
    "for num_puntos in [100, 1000, 10000, 100000]:\n",
    "    estimacion_pi = estimar_pi(num_puntos)\n",
    "    print(f\"Estimación de π con {num_puntos} puntos: {estimacion_pi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2012f54",
   "metadata": {},
   "source": [
    "### **Ejercicio 5: Análisis de Algoritmo de Ordenación por Mezcla (Merge Sort)**\n",
    "\n",
    "### **Implementación de Merge Sort:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr):\n",
    "    if len(arr) > 1:\n",
    "        medio = len(arr) // 2\n",
    "        izquierda = arr[:medio]\n",
    "        derecha = arr[medio:]\n",
    "\n",
    "        merge_sort(izquierda)\n",
    "        merge_sort(derecha)\n",
    "\n",
    "        i = j = k = 0\n",
    "\n",
    "        # Fusiona los arreglos temporales en arr[]\n",
    "        while i < len(izquierda) and j < len(derecha):\n",
    "            if izquierda[i] < derecha[j]:\n",
    "                arr[k] = izquierda[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                arr[k] = derecha[j]\n",
    "                j += 1\n",
    "            k += 1\n",
    "\n",
    "        # Verifica si quedan elementos en izquierda[]\n",
    "        while i < len(izquierda):\n",
    "            arr[k] = izquierda[i]\n",
    "            i += 1\n",
    "            k += 1\n",
    "\n",
    "        # Verifica si quedan elementos en derecha[]\n",
    "        while j < len(derecha):\n",
    "            arr[k] = derecha[j]\n",
    "            j += 1\n",
    "            k += 1\n",
    "\n",
    "# Ejemplo de uso\n",
    "import random\n",
    "import time\n",
    "\n",
    "def medir_tiempo_merge_sort(tamaño):\n",
    "    arr = [random.randint(0, tamaño) for _ in range(tamaño)]\n",
    "    inicio = time.time()\n",
    "    merge_sort(arr)\n",
    "    fin = time.time()\n",
    "    return fin - inicio\n",
    "\n",
    "tamaños = [100, 1000, 10000, 100000]\n",
    "tiempos = [medir_tiempo_merge_sort(tamaño) for tamaño in tamaños]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tamaños, tiempos, '-o')\n",
    "plt.xlabel('Tamaño del arreglo')\n",
    "plt.ylabel('Tiempo de ejecución (s)')\n",
    "plt.title('Rendimiento de Merge Sort')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca643c",
   "metadata": {},
   "source": [
    "### **Análisis:**\n",
    "\n",
    "Este código implementa y evalúa el rendimiento del algoritmo Merge Sort. Dado que Merge Sort es un algoritmo de ordenamiento por división y conquista, su tiempo de ejecución en todos los casos (mejor, promedio, y peor) es O(n log n), lo que lo hace muy eficiente y predecible en comparación con algoritmos como QuickSort, que pueden degradarse a O(n^2) en el peor caso.\n",
    "\n",
    "La función `medir_tiempo_merge_sort` genera un arreglo de tamaño `tamaño` con números aleatorios y mide el tiempo que Merge Sort tarda en ordenar este arreglo. Posteriormente, se grafican estos tiempos para diferentes tamaños de arreglos, proporcionando una visualización directa de cómo el tiempo de ejecución escala con el tamaño del problema.\n",
    "\n",
    "Este conjunto de ejercicios y soluciones abarca desde análisis de algoritmos específicos hasta el uso de técnicas estadísticas para evaluar la eficiencia algorítmica, ilustrando la importancia de la teoría algorítmica en la práctica de la programación y el análisis de datos."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
